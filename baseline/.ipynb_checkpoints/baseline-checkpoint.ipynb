{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import distance  \n",
    "import Levenshtein\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "from numba import jit\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-Levenshtein in e:\\programdata\\anaconda3\\lib\\site-packages (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install distance\n",
    "!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('data/train.csv',sep='\\t',header=None)\n",
    "train.columns=['q1','q2','label']\n",
    "test=pd.read_csv('data/test.csv',sep='\\t',header=None)\n",
    "test.columns=['q1','q2']\n",
    "test['label']=1\n",
    "sample_submit=pd.read_csv('data/sample_submit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>有哪些女明星被潜规则啦</td>\n",
       "      <td>哪些女明星被潜规则了</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>怎么支付宝绑定银行卡？</td>\n",
       "      <td>银行卡怎么绑定支付宝</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>请问这部电视剧叫什么名字</td>\n",
       "      <td>请问谁知道这部电视剧叫什么名字</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>泰囧完整版下载</td>\n",
       "      <td>エウテルペ完整版下载</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>在沧州市区哪家卖的盐焗鸡好吃？</td>\n",
       "      <td>沧州饭店哪家便宜又好吃又实惠</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                q1               q2  label\n",
       "0      有哪些女明星被潜规则啦       哪些女明星被潜规则了      1\n",
       "1      怎么支付宝绑定银行卡？       银行卡怎么绑定支付宝      1\n",
       "2     请问这部电视剧叫什么名字  请问谁知道这部电视剧叫什么名字      1\n",
       "3          泰囧完整版下载       エウテルペ完整版下载      0\n",
       "4  在沧州市区哪家卖的盐焗鸡好吃？   沧州饭店哪家便宜又好吃又实惠      0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   q1      5000 non-null   object\n",
      " 1   q2      5000 non-null   object\n",
      " 2   label   5000 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   q1      5000 non-null   object\n",
      " 1   q2      5000 non-null   object\n",
      " 2   label   5000 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5784\n",
       "0    0.4216\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([train,test],axis=0).reset_index(drop=True)\n",
    "train_size=len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 基础特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本长度特征\n",
    "data['q1_len']=data['q1'].astype(str).map(len)\n",
    "data['q2_len']=data['q2'].astype(str).map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10000.000000\n",
       "mean        10.658400\n",
       "std          4.019095\n",
       "min          3.000000\n",
       "25%          8.000000\n",
       "50%         10.000000\n",
       "75%         12.000000\n",
       "max         49.000000\n",
       "Name: q1_len, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['q1_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长度差特征：差/比例\n",
    "data['q1q2_len_diff']=data['q1_len']-data['q2_len']\n",
    "data['q1q2_len_diff_abs']=np.abs(data['q1_len']-data['q2_len'])\n",
    "data['q1q2_rate']=data['q1_len']/data['q2_len']\n",
    "data['q2q1_rate']=data['q2_len']/data['q1_len']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 特殊符号特征\n",
    "data['q1_end_special']=data['q1'].str.endswith('？').astype(int)\n",
    "data['q2_end_special']=data['q2'].str.endswith('？').astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 共现字特征\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comm_q1q2char_nums']=data.apply(lambda  row:len(set(row['q1'])&set(row['q2'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共现字位置\n",
    "def char_match_pos(q1, q2, pos_i):\n",
    "    q1 = list(q1)\n",
    "    q2 = list(q2)\n",
    "\n",
    "    if pos_i < len(q1):\n",
    "        q2_len = min(len(q2), 25)  # q2_len只匹配前25个字\n",
    "        for pos_j in range(q2_len):\n",
    "            if q1[pos_i] == q2[pos_j]:\n",
    "                q_pos = pos_j + 1  # 如果匹配上了 记录匹配的位置\n",
    "                break\n",
    "            elif pos_j == q2_len - 1:\n",
    "                q_pos = 0  # 如果没有匹配上 赋值为0\n",
    "    else:\n",
    "        q_pos = -1  # 如果后续长度不存在 赋值为-1\n",
    "\n",
    "    return q_pos\n",
    "\n",
    "\n",
    "for pos_i in range(8):\n",
    "    data['q1_pos_' + str(pos_i + 1)] = data.apply(\n",
    "        lambda row: char_match_pos(row['q1'], row['q2'], pos_i), axis=1).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里也可以用结巴分词，改成“词”粒度的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 距离特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "距离特征:   0%|                                                                                                                                                                                                                                             | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========距离特征 =============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "距离特征: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.84s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"===========距离特征 =============\")\n",
    "sim_func_dict = {\"jaccard\": distance.jaccard,\n",
    "                 \"sorensen\": distance.sorensen,\n",
    "                 \"levenshtein\": distance.levenshtein,\n",
    "                 \"ratio\": Levenshtein.ratio\n",
    "                 }\n",
    "\n",
    "for sim_func in tqdm(sim_func_dict, desc=\"距离特征\"):\n",
    "    data[sim_func] = data.apply(lambda row: sim_func_dict[sim_func](row[\"q1\"],row[\"q2\"]), axis=1)\n",
    "    qt = [[3, 3], [3, 5], [5, 5], [5, 10], [10, 10], [10, 15], [15, 15], [15, 25]]\n",
    "\n",
    "    for qt_len in qt:\n",
    "        if qt_len[0] == 3 and sim_func == \"levenshtein\":\n",
    "            pass\n",
    "        else:\n",
    "            data[sim_func + '_q' + str(qt_len[0]) + '_t' + str(qt_len[1])] = data.apply(\n",
    "                lambda row: sim_func_dict[sim_func](row[\"q1\"][:qt_len[0]],\n",
    "                                                    row[\"q2\"][:qt_len[1]]),\n",
    "                axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 文本向量匹配特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import jieba\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['q1_words_list']=data['q1'].apply(lambda x:[w for w in jieba.cut(x) if w])\n",
    "data['q2_words_list']=data['q2'].apply(lambda x:[w for w in jieba.cut(x) if w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences=[]\n",
    "# for sent in (data['q1']+data['q2']):\n",
    "#     sentences.append([w for w in jieba.cut(sent) if w])\n",
    "sentences=data['q1_words_list'].values.tolist()+data['q2_words_list'].values.tolist()\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "w2v_model = word2vec.Word2Vec(sentences,\n",
    "                                  size=100, window=10, min_count=1, workers=4,\n",
    "                                  sg=1)\n",
    "w2v_model.save('models/' + 'word2vec.model')\n",
    "w2v_model.wv.save_word2vec_format('models/' + 'word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11196"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 9246.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 9074.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 11872.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 11242.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 11866.30it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 11903.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 8305.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 11867.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 9639.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 16573.85it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 15496.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 12613.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine, cityblock, canberra, euclidean, \\\n",
    "    minkowski, braycurtis, correlation, chebyshev, jensenshannon, mahalanobis, \\\n",
    "    seuclidean, sqeuclidean\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# 计算词向量的相似度\n",
    "def get_w2v(query, title, num):\n",
    "    q = np.zeros(100)\n",
    "    count = 0\n",
    "    for w in query:\n",
    "        if w in w2v_model.wv:\n",
    "            q += w2v_model.wv[w]\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        query_vec = q\n",
    "    query_vec = (q / count).tolist()\n",
    "\n",
    "    t = np.zeros(100)\n",
    "    count = 0\n",
    "    for w in title:\n",
    "        if w in w2v_model.wv:\n",
    "            t += w2v_model.wv[w]\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        title_vec = q\n",
    "    title_vec = (t / count).tolist()\n",
    "\n",
    "    if num == 1:\n",
    "        try:\n",
    "            vec_cosine = cosine(query_vec, title_vec)\n",
    "            return vec_cosine\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    if num == 2:\n",
    "        try:\n",
    "            vec_canberra = canberra(query_vec, title_vec) / len(query_vec)\n",
    "            return vec_canberra\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    if num == 3:\n",
    "        try:\n",
    "            vec_cityblock = cityblock(query_vec, title_vec) / len(query_vec)\n",
    "            return vec_cityblock\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    if num == 4:\n",
    "        try:\n",
    "            vec_euclidean = euclidean(query_vec, title_vec)\n",
    "            return vec_euclidean\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    if num == 5:\n",
    "        try:\n",
    "            vec_braycurtis = braycurtis(query_vec, title_vec)\n",
    "            return vec_braycurtis\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    if num == 6:\n",
    "        try:\n",
    "            vec_minkowski = minkowski(query_vec, title_vec)\n",
    "            return vec_minkowski\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    if num == 7:\n",
    "        try:\n",
    "            vec_correlation = correlation(query_vec, title_vec)\n",
    "            return vec_correlation\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "\n",
    "    if num == 8:\n",
    "        try:\n",
    "            vec_chebyshev = chebyshev(query_vec, title_vec)\n",
    "            return vec_chebyshev\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "\n",
    "    if num == 9:\n",
    "        try:\n",
    "            vec_jensenshannon = jensenshannon(query_vec, title_vec)\n",
    "            return vec_jensenshannon\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "\n",
    "    if num == 10:\n",
    "        try:\n",
    "            vec_mahalanobis = mahalanobis(query_vec, title_vec)\n",
    "            return vec_mahalanobis\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "\n",
    "    if num == 11:\n",
    "        try:\n",
    "            vec_seuclidean = seuclidean(query_vec, title_vec)\n",
    "            return vec_seuclidean\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "    if num == 12:\n",
    "        try:\n",
    "            vec_sqeuclidean = sqeuclidean(query_vec, title_vec)\n",
    "            return vec_sqeuclidean\n",
    "        except Exception as e:\n",
    "            return 0\n",
    "# 词向量的相似度特征\n",
    "data['vec_cosine'] = data.progress_apply(lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 1),\n",
    "                                         axis=1)\n",
    "data['vec_canberra'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 2), axis=1)\n",
    "data['vec_cityblock'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 3), axis=1)\n",
    "data['vec_euclidean'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 4), axis=1)\n",
    "data['vec_braycurtis'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 5), axis=1)\n",
    "data['vec_minkowski'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 6), axis=1)\n",
    "data['vec_correlation'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 7), axis=1)\n",
    "\n",
    "data['vec_chebyshev'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 8), axis=1)\n",
    "data['vec_jensenshannon'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 9), axis=1)\n",
    "data['vec_mahalanobis'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 10), axis=1)\n",
    "data['vec_seuclidean'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 11), axis=1)\n",
    "data['vec_sqeuclidean'] = data.progress_apply(\n",
    "    lambda index: get_w2v(index['q1_words_list'], index['q2_words_list'], 12), axis=1)\n",
    "\n",
    "data['vec_cosine'] = data['vec_cosine'].astype('float32')\n",
    "data['vec_canberra'] = data['vec_canberra'].astype('float32')\n",
    "data['vec_cityblock'] = data['vec_cityblock'].astype('float32')\n",
    "data['vec_euclidean'] = data['vec_euclidean'].astype('float32')\n",
    "data['vec_braycurtis'] = data['vec_braycurtis'].astype('float32')\n",
    "data['vec_correlation'] = data['vec_correlation'].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 向量特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 11688.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 10459.07it/s]\n"
     ]
    }
   ],
   "source": [
    "def w2v_sent2vec(words):\n",
    "    \"\"\"计算句子的平均word2vec向量, sentences是一个句子, 句向量最后会归一化\"\"\"\n",
    "\n",
    "    M = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            M.append(w2v_model.wv[word])\n",
    "        except KeyError:  # 不在词典里\n",
    "            continue\n",
    "\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    return (v / np.sqrt((v ** 2).sum())).astype(np.float32).tolist()\n",
    "\n",
    "\n",
    "fea_names = ['q1_vec_{}'.format(i) for i in range(100)]\n",
    "data[fea_names] = data.progress_apply(lambda row: w2v_sent2vec(row['q1_words_list']), result_type='expand', axis=1)\n",
    "\n",
    "fea_names = ['q2_vec_{}'.format(i) for i in range(100)]\n",
    "data[fea_names] = data.progress_apply(lambda row: w2v_sent2vec(row['q2_words_list']), result_type='expand', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['q1', 'q2', 'label', 'q1_len', 'q2_len', 'q1q2_len_diff',\n",
       "       'q1q2_len_diff_abs', 'q1q2_rate', 'q2q1_rate', 'q1_end_special',\n",
       "       ...\n",
       "       'q2_vec_90', 'q2_vec_91', 'q2_vec_92', 'q2_vec_93', 'q2_vec_94',\n",
       "       'q2_vec_95', 'q2_vec_96', 'q2_vec_97', 'q2_vec_98', 'q2_vec_99'],\n",
       "      dtype='object', length=268)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_feas=['q1','q2','label','q1_words_list','q2_words_list']\n",
    "features=[col for col in data.columns if col not in no_feas]\n",
    "\n",
    "train,test=data[:train_size],data[train_size:]\n",
    "len(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[features] # 训练集输入\n",
    "y = train['label'] # 训练集标签\n",
    "X_test = test[features] # 测试集输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = KFold(n_splits=n_fold, shuffle=True,random_state=1314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.35115\tvalid_1's binary_logloss: 0.4005\n",
      "[100]\ttraining's binary_logloss: 0.30881\tvalid_1's binary_logloss: 0.383732\n",
      "[150]\ttraining's binary_logloss: 0.281047\tvalid_1's binary_logloss: 0.381533\n",
      "[200]\ttraining's binary_logloss: 0.258899\tvalid_1's binary_logloss: 0.378913\n",
      "[250]\ttraining's binary_logloss: 0.239865\tvalid_1's binary_logloss: 0.381134\n",
      "[300]\ttraining's binary_logloss: 0.223461\tvalid_1's binary_logloss: 0.382063\n",
      "[350]\ttraining's binary_logloss: 0.208804\tvalid_1's binary_logloss: 0.383046\n",
      "[400]\ttraining's binary_logloss: 0.195148\tvalid_1's binary_logloss: 0.383834\n",
      "Early stopping, best iteration is:\n",
      "[209]\ttraining's binary_logloss: 0.25532\tvalid_1's binary_logloss: 0.377958\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.352413\tvalid_1's binary_logloss: 0.394427\n",
      "[100]\ttraining's binary_logloss: 0.31011\tvalid_1's binary_logloss: 0.377531\n",
      "[150]\ttraining's binary_logloss: 0.282802\tvalid_1's binary_logloss: 0.373996\n",
      "[200]\ttraining's binary_logloss: 0.260997\tvalid_1's binary_logloss: 0.371356\n",
      "[250]\ttraining's binary_logloss: 0.242293\tvalid_1's binary_logloss: 0.372197\n",
      "[300]\ttraining's binary_logloss: 0.225798\tvalid_1's binary_logloss: 0.370962\n",
      "[350]\ttraining's binary_logloss: 0.21117\tvalid_1's binary_logloss: 0.372715\n",
      "[400]\ttraining's binary_logloss: 0.197912\tvalid_1's binary_logloss: 0.374134\n",
      "[450]\ttraining's binary_logloss: 0.185922\tvalid_1's binary_logloss: 0.376097\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttraining's binary_logloss: 0.228235\tvalid_1's binary_logloss: 0.370444\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.356451\tvalid_1's binary_logloss: 0.369811\n",
      "[100]\ttraining's binary_logloss: 0.315404\tvalid_1's binary_logloss: 0.35627\n",
      "[150]\ttraining's binary_logloss: 0.288597\tvalid_1's binary_logloss: 0.351986\n",
      "[200]\ttraining's binary_logloss: 0.266402\tvalid_1's binary_logloss: 0.352236\n",
      "[250]\ttraining's binary_logloss: 0.248007\tvalid_1's binary_logloss: 0.352131\n",
      "[300]\ttraining's binary_logloss: 0.231503\tvalid_1's binary_logloss: 0.351722\n",
      "[350]\ttraining's binary_logloss: 0.216832\tvalid_1's binary_logloss: 0.353701\n",
      "[400]\ttraining's binary_logloss: 0.203364\tvalid_1's binary_logloss: 0.357624\n",
      "[450]\ttraining's binary_logloss: 0.191294\tvalid_1's binary_logloss: 0.357435\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's binary_logloss: 0.238886\tvalid_1's binary_logloss: 0.350956\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.363584\tvalid_1's binary_logloss: 0.35444\n",
      "[100]\ttraining's binary_logloss: 0.32308\tvalid_1's binary_logloss: 0.331687\n",
      "[150]\ttraining's binary_logloss: 0.296587\tvalid_1's binary_logloss: 0.321597\n",
      "[200]\ttraining's binary_logloss: 0.274716\tvalid_1's binary_logloss: 0.318173\n",
      "[250]\ttraining's binary_logloss: 0.256062\tvalid_1's binary_logloss: 0.318071\n",
      "[300]\ttraining's binary_logloss: 0.239409\tvalid_1's binary_logloss: 0.317959\n",
      "[350]\ttraining's binary_logloss: 0.224303\tvalid_1's binary_logloss: 0.31517\n",
      "[400]\ttraining's binary_logloss: 0.210476\tvalid_1's binary_logloss: 0.316284\n",
      "[450]\ttraining's binary_logloss: 0.198738\tvalid_1's binary_logloss: 0.316459\n",
      "[500]\ttraining's binary_logloss: 0.187647\tvalid_1's binary_logloss: 0.317701\n",
      "[550]\ttraining's binary_logloss: 0.177055\tvalid_1's binary_logloss: 0.31893\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's binary_logloss: 0.221551\tvalid_1's binary_logloss: 0.313709\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\ttraining's binary_logloss: 0.348178\tvalid_1's binary_logloss: 0.409384\n",
      "[100]\ttraining's binary_logloss: 0.306807\tvalid_1's binary_logloss: 0.394699\n",
      "[150]\ttraining's binary_logloss: 0.279593\tvalid_1's binary_logloss: 0.390031\n",
      "[200]\ttraining's binary_logloss: 0.257536\tvalid_1's binary_logloss: 0.388654\n",
      "[250]\ttraining's binary_logloss: 0.239142\tvalid_1's binary_logloss: 0.390183\n",
      "[300]\ttraining's binary_logloss: 0.223051\tvalid_1's binary_logloss: 0.388555\n",
      "[350]\ttraining's binary_logloss: 0.20822\tvalid_1's binary_logloss: 0.390418\n",
      "[400]\ttraining's binary_logloss: 0.194614\tvalid_1's binary_logloss: 0.391067\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's binary_logloss: 0.255565\tvalid_1's binary_logloss: 0.387657\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 5,\n",
    "    'max_depth': 6,\n",
    "    'min_data_in_leaf': 450,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5,\n",
    "    'lambda_l1': 1,  \n",
    "    'lambda_l2': 0.001,  # 越小l2正则程度越高\n",
    "    'min_gain_to_split': 0.2,\n",
    "}\n",
    " \n",
    "oof = np.zeros(len(X))\n",
    "prediction = np.zeros(len(X_test))\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(X)):\n",
    "    X_train, X_valid = X[features].iloc[train_index], X[features].iloc[valid_index]\n",
    "    y_train, y_valid = y[train_index], y[valid_index]\n",
    "    model = lgb.LGBMRegressor(**params, n_estimators=50000, n_jobs=-1)\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              eval_metric='binary_logloss',\n",
    "              verbose=50, early_stopping_rounds=200)\n",
    "    y_pred_valid = model.predict(X_valid)\n",
    "    y_pred = model.predict(X_test, num_iteration=model.best_iteration_)\n",
    "    oof[valid_index] = y_pred_valid.reshape(-1, )\n",
    "    prediction += y_pred\n",
    "prediction /= n_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.839"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = (oof > 0.5)\n",
    "# score=accuracy_score(np.round(abs(oof)) ,train['label'].values)\n",
    "score=accuracy_score(y_pred ,train['label'].values)\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_pred = (prediction > 0.5).astype(int)\n",
    "sample_submit['label']=sub_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submit[['label']].to_csv('lgb.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2928\n",
       "0    2072\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submit['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
